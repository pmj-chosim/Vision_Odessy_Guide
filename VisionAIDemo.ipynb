{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 이미지분석\n",
    "2. custom vision- clssification\n",
    "3. face \n",
    "4. OCR\n",
    "5. Video Indexer\n",
    "\n",
    "# Azure AI Vision 솔루션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* .NET 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div></div><div></div><div><strong>Installed Packages</strong><ul><li><span>Azure.AI.Vision.ImageAnalysis, 1.0.0-beta.2</span></li><li><span>Microsoft.Azure.CognitiveServices.Vision.Face, 2.8.0-preview.3</span></li><li><span>Microsoft.Extensions.Configuration.Json, 3.1.3</span></li><li><span>System.Drawing.Common, 4.7.0</span></li></ul></div></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#r \"nuget: Microsoft.Extensions.Configuration.Json, 3.1.3\" \n",
    "#r \"nuget: System.Drawing.Common, 4.7.0\" \n",
    "#r \"nuget: Microsoft.Azure.CognitiveServices.Vision.Face, 2.8.0-preview.3\"\n",
    "#r \"nuget: Azure.AI.Vision.ImageAnalysis, 1.0.0-beta.2\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* namespace 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "using System;\n",
    "using System.IO;\n",
    "using System.Net.Http;\n",
    "using System.Net.Http.Headers;\n",
    "using System.Text;\n",
    "using System.Text.Json;\n",
    "using System.Threading.Tasks;\n",
    "using System.Drawing;\n",
    "using Microsoft.Extensions.Configuration;\n",
    "using Azure;\n",
    "using System.Linq;\n",
    "using System.Collections.Generic;\n",
    "using System.Threading;\n",
    "using Azure.AI.Vision.ImageAnalysis;\n",
    "using Microsoft.Azure.CognitiveServices.Vision.Face;\n",
    "using Microsoft.Azure.CognitiveServices.Vision.Face.Models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 이미지 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// 사용할 이미지의 주소 가져오기\n",
    "string address_1=\"C:\\\\Users\\\\parkm\\\\Desktop\\\\Vision\\\\mslearn-ai-vision\\\\Labfiles\\\\01-analyze-images\\\\C-Sharp\\\\image-analysis\\\\\";\n",
    "public string imageFile = address_1+\"images/street.jpg\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//API 사용을 위한 인증 절차\n",
    "public string aiSvcEndpoint = \"https://fruit-train.cognitiveservices.azure.com/\";\n",
    "public string aiSvcKey =\"68309624561e49688c4cbc6143304744\";\n",
    "\n",
    "public var client = new ImageAnalysisClient(new Uri(aiSvcEndpoint), new AzureKeyCredential(aiSvcKey));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//이미지 분석 API 처리 함수\n",
    "public static void AnalyzeImage(string imageFile, ImageAnalysisClient client)\n",
    "        {\n",
    "            Console.WriteLine($\"\\nAnalyzing {imageFile} \\n\");\n",
    "\n",
    "            // 이미지 파일을 전달할 수 있도록 파일 스트림 형태로 바꾸기\n",
    "            using FileStream stream = new FileStream(imageFile,\n",
    "                                                     FileMode.Open);\n",
    "\n",
    "            // 이미지 분석 결과 가져오기\n",
    "            ImageAnalysisResult result = client.Analyze(\n",
    "                BinaryData.FromStream(stream),\n",
    "                VisualFeatures.Caption | VisualFeatures.DenseCaptions | VisualFeatures.Objects | VisualFeatures.Tags | VisualFeatures.People);\n",
    "                        \n",
    "            \n",
    "            // 가장 정확한 이미지 분석 결과 출력\n",
    "            if (result.Caption.Text != null)\n",
    "            {\n",
    "                Console.WriteLine(\" Caption:\");\n",
    "                Console.WriteLine($\"   \\\"{result.Caption.Text}\\\", 신뢰도 {result.Caption.Confidence:0.00}\\n\");\n",
    "            }\n",
    "\n",
    "            // 이미지에 대한 다양한 분석 결과 출력\n",
    "            Console.WriteLine(\" Dense Captions:\");\n",
    "            foreach (DenseCaption denseCaption in result.DenseCaptions.Values)\n",
    "            {\n",
    "                Console.WriteLine($\"   Caption: '{denseCaption.Text}', 신뢰도: {denseCaption.Confidence:0.00}\");\n",
    "            }\n",
    "\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing C:\\Users\\parkm\\Desktop\\Vision\\mslearn-ai-vision\\Labfiles\\01-analyze-images\\C-Sharp\\image-analysis\\images/street.jpg \n",
      "\n",
      " Caption:\n",
      "   \"a man walking a dog on a leash on a street\", 신뢰도 0.82\n",
      "\n",
      " Dense Captions:\n",
      "   Caption: 'a man walking a dog on a leash on a street', 신뢰도: 0.82\n",
      "   Caption: 'a man walking on a street', 신뢰도: 0.69\n",
      "   Caption: 'a yellow car on the street', 신뢰도: 0.78\n",
      "   Caption: 'a black dog walking on the street', 신뢰도: 0.75\n",
      "   Caption: 'a blurry image of a blue car', 신뢰도: 0.82\n",
      "   Caption: 'a yellow taxi cab on the street', 신뢰도: 0.72\n"
     ]
    }
   ],
   "source": [
    "// 이미지 분석\n",
    "AnalyzeImage(imageFile, client);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    " // 이미지 배경화면 제거 API 처리 함수\n",
    "public static async Task BackgroundForeground(string imageFile, string endpoint, string key){\n",
    "           \n",
    "            Console.WriteLine($\" Background removal:\");\n",
    "            // API 버전과 모드 지정\n",
    "            string apiVersion = \"2023-02-01-preview\";\n",
    "            string mode = \"backgroundRemoval\"; // \"foregroundMatting\" 또는 \"backgroundRemoval\" 지정 가능\n",
    "            string url = $\"computervision/imageanalysis:segment?api-version={apiVersion}&mode={mode}\";\n",
    "\n",
    "            // API 호출\n",
    "            using (var client = new HttpClient())\n",
    "            {\n",
    "                var contentType = new MediaTypeWithQualityHeaderValue(\"application/json\");\n",
    "                client.BaseAddress = new Uri(endpoint);\n",
    "                client.DefaultRequestHeaders.Accept.Add(contentType);\n",
    "                client.DefaultRequestHeaders.Add(\"Ocp-Apim-Subscription-Key\", key);\n",
    "\n",
    "                var data = new{\n",
    "                    url = $\"https://github.com/MicrosoftLearning/mslearn-ai-vision/blob/main/Labfiles/01-analyze-images/Python/image-analysis/images/street.jpg?raw=true\"\n",
    "                };\n",
    "\n",
    "                var jsonData = JsonSerializer.Serialize(data);\n",
    "                var contentData = new StringContent(jsonData, Encoding.UTF8, contentType);\n",
    "                var response = await client.PostAsync(url, contentData);\n",
    "\n",
    "                File.WriteAllBytes(\"background.png\", response.Content.ReadAsByteArrayAsync().Result);\n",
    "                Console.WriteLine(\"  Results saved in background.png\\n\");\n",
    "                \n",
    "            }\n",
    "            \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Background removal:\n",
      "  Results saved in background.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// 배경 제거\n",
    "await BackgroundForeground(imageFile, aiSvcEndpoint, aiSvcKey);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.얼굴 감지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Computer Vision (얼굴 이정표)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// 사용할 이미지의 주소 가져오기\n",
    "public string imageFile = \"C:/Users/parkm/Desktop/Vision/mslearn-ai-vision/Labfiles/04-face/C-Sharp/computer-vision/images/people.jpg\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//API 사용을 위한 인증 절차\n",
    "var aiSvcEndpoint = \"https://fruit-train.cognitiveservices.azure.com/\";\n",
    "var aiSvcKey = \"3446cc4f896148e79b4864c0d86fd497\";\n",
    "\n",
    "public var client = new ImageAnalysisClient(\n",
    "    new Uri(aiSvcEndpoint),\n",
    "    new AzureKeyCredential(aiSvcKey)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//얼굴 이정표 분석 API 처리 함수\n",
    "public static void AnalyzeImage(string imageFile, ImageAnalysisClient client)\n",
    "{\n",
    "    Console.WriteLine($\"\\nAnalyzing {imageFile} \\n\");\n",
    "\n",
    "    // 이미지 파일을 전달할 수 있도록 파일 스트림 형태로 바꾸기\n",
    "    using FileStream stream = new FileStream(imageFile, FileMode.Open);\n",
    "\n",
    "    // 이미지에 있는 사람 감지 결과 가져오기\n",
    "    ImageAnalysisResult result = client.Analyze(\n",
    "        BinaryData.FromStream(stream),\n",
    "        VisualFeatures.People);\n",
    "\n",
    "    // 감지 결과 출력하기\n",
    "    Console.WriteLine($\"이미지에서의 얼굴 분석 결과:\");\n",
    "    Console.WriteLine($\" Metadata: Model: {result.ModelVersion} Image dimensions: {result.Metadata.Width} x {result.Metadata.Height}\");\n",
    "    Console.WriteLine($\" 분석된 사람들:\");\n",
    "    foreach (DetectedPerson person in result.People.Values)\n",
    "    {\n",
    "        if(person.Confidence > 0.3)\n",
    "            Console.WriteLine($\"   사람 : Bounding box {person.BoundingBox.ToString()}, 정확도 {person.Confidence:F4}\");\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing C:/Users/parkm/Desktop/Vision/mslearn-ai-vision/Labfiles/04-face/C-Sharp/computer-vision/images/people.jpg \n",
      "\n",
      "이미지에서의 얼굴 분석 결과:\n",
      " Metadata: Model: 2023-10-01 Image dimensions: 800 x 514\n",
      " 분석된 사람들:\n",
      "   사람 : Bounding box Top: 73, Left: 454, Width: 345, Height: 439, 정확도 0.9518\n",
      "   사람 : Bounding box Top: 0, Left: 87, Width: 491, Height: 513, 정확도 0.9195\n"
     ]
    }
   ],
   "source": [
    "//얼굴 이정표 분석\n",
    "AnalyzeImage(imageFile, client);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Face API (얼굴 특징 분석)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// 사용할 이미지의 주소 가져오기\n",
    "public string imageFile = \"C:/Users/parkm/Desktop/Vision/mslearn-ai-vision/Labfiles/04-face/C-Sharp/face-api/images/people.jpg\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//API 사용을 위한 인증 절차\n",
    "string cogSvcEndpoint = \"https://fruit-train.cognitiveservices.azure.com/\";\n",
    "string cogSvcKey = \"3446cc4f896148e79b4864c0d86fd497\";\n",
    "\n",
    "Microsoft.Azure.CognitiveServices.Vision.Face.ApiKeyServiceClientCredentials credentials = new Microsoft.Azure.CognitiveServices.Vision.Face.ApiKeyServiceClientCredentials(cogSvcKey);\n",
    "\n",
    "public FaceClient client = new FaceClient(credentials)\n",
    "{\n",
    "    Endpoint = cogSvcEndpoint\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//얼굴 감지 결과 출력 함수\n",
    "public static void DrawFaceAnnotations(Image image, IList<DetectedFace> detected_faces){\n",
    "        Graphics graphics = Graphics.FromImage(image);\n",
    "        Pen pen = new Pen(Color.LightGreen, 3);\n",
    "        Font font = new Font(\"Arial\", 14);\n",
    "        SolidBrush brush = new SolidBrush(Color.White);\n",
    "        int faceCount = 0;\n",
    "\n",
    "        foreach (var face in detected_faces){\n",
    "            faceCount++;\n",
    "            Console.WriteLine($\"\\nFace number {faceCount}\");\n",
    "\n",
    "            Console.WriteLine($\" - 입을 다물고 있는지 여부: {face.FaceAttributes.Occlusion.MouthOccluded}\");\n",
    "            Console.WriteLine($\" - 눈을 감고 있는지 여부: {face.FaceAttributes.Occlusion.EyeOccluded}\");\n",
    "            Console.WriteLine($\" - 블러 정도: {face.FaceAttributes.Blur.BlurLevel}\");\n",
    "            Console.WriteLine($\" - 안경 착용 여부: {face.FaceAttributes.Glasses}\");\n",
    "\n",
    "            var r = face.FaceRectangle;\n",
    "            Rectangle rect = new Rectangle(r.Left, r.Top, r.Width, r.Height);\n",
    "            graphics.DrawRectangle(pen, rect);\n",
    "            string annotation = $\"Face number {faceCount}\";\n",
    "            graphics.DrawString(annotation, font, brush, r.Left, r.Top);\n",
    "        }\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//분석 결과 이미지로 저장하는 함수\n",
    "public static void SaveAnnotatedImage(Image image, string output_file){\n",
    "        image.Save(output_file);\n",
    "        Console.WriteLine(\"Results saved in \" + output_file);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//얼굴 분석 API 호출 함수\n",
    "public static async Task DetectFaces(string imageFile, FaceClient client){\n",
    "        Console.WriteLine($\"Detecting faces in {imageFile}\");\n",
    "\n",
    "        // API에게 요청할 내용 설정\n",
    "        IList<FaceAttributeType> features = new FaceAttributeType[]{\n",
    "            FaceAttributeType.Occlusion, //얼굴 부분 가리는 정도\n",
    "            FaceAttributeType.Blur, //흐림 정도\n",
    "            FaceAttributeType.Glasses //안경 착용 여부\n",
    "        };\n",
    "\n",
    "        using (var imageData = File.OpenRead(imageFile)){\n",
    "            var detected_faces = await client.Face.DetectWithStreamAsync(imageData, returnFaceAttributes: features, returnFaceId: false);\n",
    "\n",
    "            if (detected_faces.Count() > 0){\n",
    "                Console.WriteLine($\"{detected_faces.Count()} faces detected.\");\n",
    "\n",
    "                Image image = Image.FromFile(imageFile);\n",
    "                DrawFaceAnnotations(image, detected_faces);\n",
    "\n",
    "                string output_file = \"detected_faces.jpg\";\n",
    "                SaveAnnotatedImage(image, output_file);\n",
    "            }\n",
    "        }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting faces in C:/Users/parkm/Desktop/Vision/mslearn-ai-vision/Labfiles/04-face/C-Sharp/face-api/images/people.jpg\n",
      "2 faces detected.\n",
      "\n",
      "Face number 1\n",
      " - 입을 다물고 있는지 여부: False\n",
      " - 눈을 감고 있는지 여부: False\n",
      " - 블러 정도: Low\n",
      " - 안경 착용 여부: NoGlasses\n",
      "\n",
      "Face number 2\n",
      " - 입을 다물고 있는지 여부: False\n",
      " - 눈을 감고 있는지 여부: False\n",
      " - 블러 정도: Low\n",
      " - 안경 착용 여부: ReadingGlasses\n",
      "Results saved in detected_faces.jpg\n"
     ]
    }
   ],
   "source": [
    "//얼굴 특징 분석 \n",
    "await DetectFaces(imageFile, client);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//API 사용을 위한 인증 절차\n",
    "public string aiSvcEndpoint = \"https://fruit-train.cognitiveservices.azure.com/\";\n",
    "public string aiSvcKey = \"68309624561e49688c4cbc6143304744\";\n",
    "\n",
    "\n",
    "public ImageAnalysisClient client = new ImageAnalysisClient(\n",
    "    new Uri(aiSvcEndpoint),\n",
    "    new AzureKeyCredential(aiSvcKey)\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// 분석 결과 출력 함수\n",
    "public static void DrawTextAndSaveImage(ImageAnalysisResult result, System.Drawing.Image image, Graphics graphics, Pen pen){\n",
    "    foreach (var line in result.Read.Blocks.SelectMany(block => block.Lines)){\n",
    "        // 분석 결과 텍스트로 출력\n",
    "        Console.WriteLine($\"   '{line.Text}'\");\n",
    "        var drawLinePolygon = true;\n",
    "        Console.WriteLine($\"   바운딩 영역 : [{string.Join(\" \", line.BoundingPolygon)}]\");   \n",
    "        foreach (DetectedTextWord word in line.Words){\n",
    "            Console.WriteLine($\"     단어: '{word.Text}', 신뢰도 {word.Confidence:F4}, 바운딩 영역: [{string.Join(\" \", word.BoundingPolygon)}]\");             \n",
    "            drawLinePolygon = false;\n",
    "            var r = word.BoundingPolygon;\n",
    "            Point[] polygonPoints = {\n",
    "                new Point(r[0].X, r[0].Y), new Point(r[1].X, r[1].Y), new Point(r[2].X, r[2].Y), new Point(r[3].X, r[3].Y)\n",
    "            };\n",
    "            graphics.DrawPolygon(pen, polygonPoints);\n",
    "        }\n",
    "        // 이미지 내에서 텍스트가 감지된 영역 정보 저장\n",
    "        if (drawLinePolygon){\n",
    "            var r = line.BoundingPolygon;\n",
    "            Point[] polygonPoints = {\n",
    "                new Point(r[0].X, r[0].Y), new Point(r[1].X, r[1].Y), new Point(r[2].X, r[2].Y), new Point(r[3].X, r[3].Y)\n",
    "            };\n",
    "            graphics.DrawPolygon(pen, polygonPoints);\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//이미지 위에 텍스트 영역 표시 및 저장 함수\n",
    "public static void DisplayAndSaveResults(string imageFile, ImageAnalysisResult result){\n",
    "    Console.WriteLine($\"Text:\");\n",
    "    System.Drawing.Image image = System.Drawing.Image.FromFile(imageFile);\n",
    "    Graphics graphics = Graphics.FromImage(image);\n",
    "    Pen pen = new Pen(Color.Cyan, 3);\n",
    "    \n",
    "    DrawTextAndSaveImage(result, image, graphics, pen);\n",
    "\n",
    "    // 분석 내용이 반영된 이미지 저장\n",
    "    string output_file = \"text.jpg\";\n",
    "    image.Save(output_file);\n",
    "    Console.WriteLine(\"\\nResults saved in \" + output_file + \"\\n\");\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "//OCR API 호출 함수\n",
    "public static void GetTextRead(string imageFile, ImageAnalysisClient client){\n",
    "    Console.WriteLine($\"\\nReading text from {imageFile} \\n\");\n",
    "\n",
    "    // 이미지를 파일 스트림 형태로 변환\n",
    "    using FileStream stream = new FileStream(imageFile, FileMode.Open);\n",
    "\n",
    "    // 이미지 분석 결과 받기\n",
    "    ImageAnalysisResult result = client.Analyze(\n",
    "        BinaryData.FromStream(stream),\n",
    "        VisualFeatures.Read);\n",
    "                \n",
    "    stream.Close();\n",
    "                \n",
    "    // 분석 결과 보여주기\n",
    "    DisplayAndSaveResults(imageFile, result);\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "// 사용할 이미지의 주소 일부 가져오기\n",
    " public static String address_3=\"C:\\\\Users\\\\parkm\\\\Desktop\\\\Vision\\\\mslearn-ai-vision\\\\Labfiles\\\\05-ocr\\\\C-Sharp\\\\read-text\\\\images\\\\\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading text from C:\\Users\\parkm\\Desktop\\Vision\\mslearn-ai-vision\\Labfiles\\05-ocr\\C-Sharp\\read-text\\images\\Lincoln.jpg \n",
      "\n",
      "Text:\n",
      "   'IN THIS TEMPLE'\n",
      "   Bounding Polygon: [(328, 171) (477, 169) (477, 184) (328, 186)]\n",
      "     Word: 'IN', Confidence 0.9930, Bounding Polygon: [(328, 171) (342, 171) (342, 187) (328, 187)]\n",
      "     Word: 'THIS', Confidence 0.9910, Bounding Polygon: [(357, 171) (397, 170) (397, 185) (357, 186)]\n",
      "     Word: 'TEMPLE', Confidence 0.9930, Bounding Polygon: [(407, 170) (474, 170) (474, 184) (407, 185)]\n",
      "   'AS IN THE HEARTS OF THE PEOPLE'\n",
      "   Bounding Polygon: [(240, 193) (564, 188) (564, 203) (240, 210)]\n",
      "     Word: 'AS', Confidence 0.9950, Bounding Polygon: [(241, 194) (262, 194) (262, 210) (241, 211)]\n",
      "     Word: 'IN', Confidence 0.9980, Bounding Polygon: [(270, 193) (284, 193) (284, 210) (270, 210)]\n",
      "     Word: 'THE', Confidence 0.9930, Bounding Polygon: [(298, 193) (332, 192) (332, 208) (298, 209)]\n",
      "     Word: 'HEARTS', Confidence 0.9940, Bounding Polygon: [(340, 192) (410, 191) (410, 207) (340, 208)]\n",
      "     Word: 'OF', Confidence 0.9930, Bounding Polygon: [(420, 190) (444, 190) (444, 206) (420, 206)]\n",
      "     Word: 'THE', Confidence 0.9930, Bounding Polygon: [(452, 190) (487, 189) (487, 205) (452, 206)]\n",
      "     Word: 'PEOPLE', Confidence 0.9960, Bounding Polygon: [(495, 189) (562, 188) (562, 204) (495, 205)]\n",
      "   'FOR WHOM HE SAVED THE UNION'\n",
      "   Bounding Polygon: [(237, 214) (568, 208) (569, 224) (237, 231)]\n",
      "     Word: 'FOR', Confidence 0.9950, Bounding Polygon: [(238, 214) (271, 213) (271, 231) (237, 231)]\n",
      "     Word: 'WHOM', Confidence 0.9880, Bounding Polygon: [(281, 213) (339, 212) (339, 229) (281, 230)]\n",
      "     Word: 'HE', Confidence 0.9980, Bounding Polygon: [(355, 212) (378, 212) (378, 228) (354, 229)]\n",
      "     Word: 'SAVED', Confidence 0.9940, Bounding Polygon: [(388, 212) (441, 211) (440, 227) (388, 228)]\n",
      "     Word: 'THE', Confidence 0.9930, Bounding Polygon: [(455, 211) (491, 210) (490, 226) (455, 227)]\n",
      "     Word: 'UNION', Confidence 0.9970, Bounding Polygon: [(501, 210) (560, 209) (559, 225) (500, 226)]\n",
      "   'THE MEMORY OF ABRAHAM LINCOLN'\n",
      "   Bounding Polygon: [(226, 235) (575, 229) (576, 245) (226, 252)]\n",
      "     Word: 'THE', Confidence 0.9980, Bounding Polygon: [(228, 235) (260, 235) (260, 252) (228, 252)]\n",
      "     Word: 'MEMORY', Confidence 0.9960, Bounding Polygon: [(268, 235) (349, 234) (349, 250) (268, 251)]\n",
      "     Word: 'OF', Confidence 0.9990, Bounding Polygon: [(358, 234) (382, 234) (381, 250) (357, 250)]\n",
      "     Word: 'ABRAHAM', Confidence 0.9960, Bounding Polygon: [(389, 233) (473, 232) (472, 248) (389, 249)]\n",
      "     Word: 'LINCOLN', Confidence 0.9940, Bounding Polygon: [(488, 231) (570, 229) (570, 245) (487, 247)]\n",
      "   'IS ENSHRINED FOREVER'\n",
      "   Bounding Polygon: [(288, 255) (515, 253) (516, 268) (288, 271)]\n",
      "     Word: 'IS', Confidence 0.9960, Bounding Polygon: [(288, 256) (302, 256) (302, 272) (288, 272)]\n",
      "     Word: 'ENSHRINED', Confidence 0.9930, Bounding Polygon: [(311, 256) (416, 255) (417, 270) (311, 272)]\n",
      "     Word: 'FOREVER', Confidence 0.9950, Bounding Polygon: [(431, 255) (510, 253) (511, 268) (431, 270)]\n",
      "\n",
      "Results saved in text.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//1. Lincoln.jpg 읽기\n",
    "GetTextRead(address_3+\"Lincoln.jpg\", client);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading text from C:\\Users\\parkm\\Desktop\\Vision\\mslearn-ai-vision\\Labfiles\\05-ocr\\C-Sharp\\read-text\\images\\Note.jpg \n",
      "\n",
      "Text:\n",
      "   'Shopping List'\n",
      "   바운딩 영역 : [(231, 141) (693, 147) (691, 245) (230, 240)]\n",
      "     단어: 'Shopping', 신뢰도 0.9630, 바운딩 영역: [(240, 141) (535, 149) (531, 245) (234, 234)]\n",
      "     단어: 'List', 신뢰도 0.8300, 바운딩 영역: [(554, 149) (689, 147) (686, 244) (550, 245)]\n",
      "   'Non- Fat milk'\n",
      "   바운딩 영역 : [(149, 302) (633, 297) (633, 374) (150, 378)]\n",
      "     단어: 'Non-', 신뢰도 0.5770, 바운딩 영역: [(150, 303) (309, 301) (310, 378) (153, 378)]\n",
      "     단어: 'Fat', 신뢰도 0.8420, 바운딩 영역: [(324, 301) (438, 300) (437, 378) (325, 378)]\n",
      "     단어: 'milk', 신뢰도 0.9940, 바운딩 영역: [(476, 299) (620, 298) (617, 374) (475, 377)]\n",
      "   'Bread'\n",
      "   바운딩 영역 : [(138, 400) (382, 399) (383, 472) (138, 474)]\n",
      "     단어: 'Bread', 신뢰도 0.9950, 바운딩 영역: [(152, 400) (366, 400) (368, 471) (151, 475)]\n",
      "   'Eggs'\n",
      "   바운딩 영역 : [(146, 517) (351, 526) (348, 605) (146, 609)]\n",
      "     단어: 'Eggs', 신뢰도 0.9920, 바운딩 영역: [(149, 517) (342, 519) (341, 610) (148, 609)]\n",
      "\n",
      "Results saved in text.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//2.Note.jpg 읽기\n",
    "GetTextRead(address_3+\"Note.jpg\", client);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "languageName": "csharp",
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
